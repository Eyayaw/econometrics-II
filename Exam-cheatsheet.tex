% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Econometrics II chearsheet},
  pdfauthor={Eyayaw Beze},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Econometrics II chearsheet}
\author{Eyayaw Beze}
\date{July 20, 2020}

\begin{document}
\maketitle

\textbf{Assumptions of cross-section Regression:}

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\tightlist
\item
  The data \((y_i, x_i)\) are \textbf{\emph{inid}} over i---stratified
  random sampling.
\item
  The model is correctly specified \ldots{} says: \textbf{linear in
  parameters}, \textbf{no measurement error,} \textbf{no omitted
  variable}.
\end{enumerate}

\textbf{Advantages of panel data (pd) against cross-sectional data}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Increased precision in estimation
\item
  Solves Omitted variable bias
\item
  Dynamics of individual behavior---lagged outcome variables.\\
\end{enumerate}

\textbf{Strict-exogeneity}:
\(\mathrm{E}\left[\varepsilon_{i t} \mid \alpha_{i}, \mathbf{x}_{i 1}, \ldots, \mathbf{x}_{i T}\right]=0, \quad t=1, \ldots, T\)
i.e., that \(\varepsilon_{i t}\) has mean zero conditional on past,
current and future values of \(\mathbf{x}\).

\textbf{\emph{POLS}}: most restrictive model, specifies
\textbf{constant-coefficients, uses both t and i variations.} \(u_{it}\)
is likely to be correlated over time for a given individual.
Inconsistent if fixed effects model is true. Is appropriate if the
constant-coefficients or RE models are appropriate, but panel-corrected
standard errors and t-stats must be used for inference. However,
\(\boldsymbol{\hat\beta}_{\text {POLS }}\) will be inefficient and a
standard variance matrix is wrong unless additional assumptions of
\textbf{homoskedasticity} and \textbf{no serial correlation} are
maintained.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  \(\mathrm{E}\left[u_{i t}^{2} \mathbf{x}_{i t}^{\prime} \mathbf{x}_{i t}\right]=\sigma^{2} \mathrm{E}\left[\mathbf{x}_{i t}^{\prime} \mathbf{x}_{i t}\right]\)
\item
  \(E\left[u_{i t} u_{i s} \mathbf{x}_{i t}^{\prime} \mathbf{x}_{i s}\right]=\mathbf{0}, t \neq s\)\\
\end{enumerate}

\textbf{\emph{BE}}: uses cross-section variation only. Is consistent if
\(\bar x_i\) are independent of the composite error. Inconsistent for
fixed effects model as
\(Cov(\alpha_i, x_{it} \; hence \; \bar x_{i}) \neq 0\)\\

\textbf{\emph{FE/FD}}: coefficients of time-invariant regressors are not
identified.\\
The \textbf{incidental parameters problem} implies inconsistency of
\(\beta_{LSDV}\) in short panels as only \(N \to \infty\) since there
are \(N + (T-1) + K\) parameters with only NT observations---the number
of parameters grows w/ the N. The FE estimator is efficient under the
assumption of iid errors (FE.3).
\(\left.\mathrm{E}\left[\varepsilon_{i} \varepsilon_{i}^{\prime} \mid \mathrm{x}_{i}, \alpha_{i}\right]\right]=\sigma_{u}^{2} \mathrm{I}_{T}\).

\textbf{FD} is also efficient under FD.3: (a)
\(\mathrm{E}\left[e_{i t}^{2} \mathbf{x}_{i t}^{\prime} \mathbf{x}_{i t}\right]=\sigma^{2} \mathrm{E}\left[\mathbf{x}_{i t}^{\prime} \mathbf{x}_{i t}\right]\)
(b)
\(\mathrm{E}\left[e_{i t} e_{i s} \mathbf{x}_{i t}^{\prime} \mathbf{x}_{i s}\right]=\mathbf{0}, t \neq s\)
where \(e=\Delta \varepsilon_{i t},\) yielding the error structure
\(\varepsilon_{i t}=\varepsilon_{i, t-1}+e_{i t}\). FE.3 maintains that
errors are serially uncorrelated, FD.3 maintains that errors follow a
\textbf{random walk}.\\
with homoskedastic and serially uncorrelated \(\varepsilon_{it}\)
\textbf{FE} is more efficient than \textbf{FD}. FD standard errors
should be adjusted for the fact that the differenced residuals are
serially correlated. POLS leaves \(\alpha_i\) completely in the error
term and RE only partly---less inconsistent. FE and FD estimators used
to control for fixed effects typically remove both good and bad
variation---susceptible to \textbf{attenuation bias} from measurement
error.

\begin{itemize}
\tightlist
\item
  \textbf{RE}: inconsistent if the true model is the one with fixed
  effects. Treats \(\alpha_i\) as unobserved random variable that is
  uncorrelated with the observed regressors \(\mathbf{x}_{i}\). Because
  the omitted variable in a \textbf{RE} model is uncorrelated w/
  included regressors there is no bias from ignoring it, it becomes part
  of the residuals. \(\alpha_i \; and\; \epsilon_{it}\) are
  \textbf{iid}---independent of regressors. The composite errors
  \(u_{i t}\) will be serially correlated since
  \(\operatorname{Cov}\left[u_{i t}, u_{i s}\right]=\mathrm{E}\left[\left(\alpha_{i}+\varepsilon_{i t}\right)\left(\alpha_{i}+\varepsilon_{i s}\right)\right]=\left\{\begin{array}{ll} \sigma_{\alpha}^{2}, & t \neq s \\ \sigma_{\alpha}^{2}+\sigma_{\varepsilon}^{2}, & t=s \end{array}\right.\)
  So POLS will be consistent but inefficient under the RE model. The
  most important consequence of \textbf{RE} is that the residuals for a
  given person are correlated across periods. Assumptions of the
  \textbf{RE} model: \textbf{linear CEF,
  homoskedasticity---equi-correlated errors}. The correlated between
  errors does not vary over time in the RE model.\\
  \(\lambda \to 1 \;if\; T \to \infty\) or
  \(\sigma_\alpha^2 > \sigma_\epsilon^2\): unobserved individual effects
  are important, the coefficients of time constant variables are
  difficult to estimate. \(RE \to FE\).
\end{itemize}

\textbf{correlated RE model}--RE with addition of \(\bar{x}_i\): models
the correlated between \(\alpha_i\) and \(\boldsymbol{x}_{i}\). Adding
the time average \(\bar{x}_i\) and using RE is the same as subtracting
the time average and using POLS.

\textbf{Dynamic Panel Models}:
\(y_{i t}=\gamma y_{i, t-1}+\alpha_{i}+\varepsilon_{i t}\) whenever we
expect the dependent variable to exercise some kind of
\textbf{persistence}/state dependence (SD) over time. Two sources: (1)
\textbf{true SD}: \(correlated[y_{i, t}, y_{i, t-1}] \simeq \gamma\) or
\(\alpha_i = 0\) (2) \textbf{unobserved heterogeneity}
\(correlated[y_{i, t}, y_{i, t-1}] \simeq \sigma_\epsilon^2/(\sigma_\alpha^2 + \sigma_\epsilon^2)\)
or \(\gamma = 0\)---correlated of past and current outcomes due to
unobserved individual effects.
\textbf{\textcolor{red}{All pd estimators are inconsistent if the regressors include lagged dependent variables}}.
The \textbf{FD} version of the dynamic model is inconsistent but we can
use two-period lags as an instrument for
\(correlated[y_{i, t-1}, y_{i, t-2}]\) \textbf{Arellano-Bond estimator},
but errors be serially uncorrelated. \textbf{If the lagged dependent
variables model is the correct one and you use FE, estimation of
positive treatment effects tends to be too large. If FE is the correct
model and you use lagged dependent variables your estimates tend to be
too small}.

\textbf{Mixed-Linear-Models}:
\(y_{i t}=\mathbf{z}_{i t}^{\prime} \boldsymbol{\beta}+\mathbf{w}_{i t}^{\prime} \boldsymbol{\alpha}_{i}+\varepsilon_{i t}\)
where \(\mathbf{z}_{i t}\) includes an intercept, \(\mathbf{w}_{i t}\)
is a vector of observable characteristics, \(\boldsymbol{\beta}\) is a
fixed parameter vector and \(\alpha_{i}\) is a random zero-mean vector.

\textbf{Clustered standard errors}---Abadie et.al 2007: motivation is
that unobserved components of outcomes for units within clusters are
correlated. Clustering is a \textbf{sampling design} issue when the
sampling follows a 2-stage process, a subset of clusters from a
population of clusters, units from sampled clusters. In this case the
clustering adjustment is justified by the fact that there are clusters
in the population that we do not see in the sample. An
\textbf{experimental design} issue, when clusters of units, rather than
units, are assigned to a treatment.

Clustering Matters Only if the residuals and the regressors are both
correlated Within clusters---not necessarily; what matters is the
within-cluster correlated of the product of the residuals \& the
regressors.

\(Var_{clu} \ge Var_{het}\) due to the addition of terms when
\(i \ne j\), for \(i, j \in c\).

The amount of increase is larger, the:\\
1. more positively correlated the regressors are across observations in
the same cluster (via \(x_i x_j\)) 2. more positively correlated are the
errors in the same clusters (via \(u_iu_j\)). 3. more observations are
in the same cluster. \textbf{Aggregated regressor} \(\uparrow\)CRSE even
if there is low within-cluster error correlated, because the regressor
of interest is perfectly correlated within clusters.

The researcher should assess whether the sampling process is clustered
or not, and whether the assignment mechanism is clustered. If the answer
to both is no, one should not adjust the standard errors for clustering,
irrespective of whether such an adjustment would change the standard
errors. In case of fixed effects, we need to cluster if either the
sampling or assignment to treatment was clustered. However, cluster
adjustments will only make an adjustment with fixed effects if there is
heterogeneity in treatment effects. So, if there is no heterogeneity in
the treatment effects, one need not adjust standard errors for
clustering once fixed effects are included. \emph{FE will generally not
completely control for within-cluster error correlated, so still use
CRVE. Because FE may take out correlated e.g.~within schools, but
additional correlated within classrooms possible; or serial correlated
in the error within cluster (e.g.~same persons).}
\textcolor{red}{What to cluster over?} Larger and fewer clusters have
less bias at the cost of more variability. If clusters are
\textbf{nested} rather use the broader cluster.

\hypertarget{did-is-a-version-of-fefd-estimation-using-aggregated-data.}{%
\subsection{DiD: is a version of FE/FD estimation using aggregated
data.}\label{did-is-a-version-of-fefd-estimation-using-aggregated-data.}}

\(\hat{\tau}_{D I D}=\left[\bar{Y}_{1}^{T}-\bar{Y}_{0}^{T}\right]-\left[\bar{Y}_{1}^{C}-\bar{Y}_{0}^{C}\right]\)

\begin{itemize}
\tightlist
\item
  \textbf{Stable Unit treatment Value Assumption (SUTVA)}, implies that
  treatment does not indirectly affect outcomes of the
  untreated---\textbf{no peer or GE effects}.\\
\item
  \textbf{CIA} states that conditional on \(\mathrm{x}\), the outcomes
  are independent of treatment,
  \(\mathrm{y_0, y_1 \perp \mathbf{D}\mid \mathbf{x}}.\)\\
\item
  \textbf{Common Trend}: outcome trends would be the same in both groups
  in the absence of treatment. treatment induces a deviation from this
  CT. Additional covariets make the CT assumption more credible.\\
\item
  \textbf{Common Support}: overlap between treated \& untreated
  subsamples \(\mathrm{0<Pr[\mathbf{D}=1\mid \mathbf{x}]}\).\\
\item
  \textbf{CMA/No Effect Prior to Treatment(NEPT)}
  \(\mathrm{E\bigl[y_0\mid D=1,\mathbf{x}\bigr]=E\bigl[y_0\mid D=0,\mathbf{x}\bigr]=E\bigl[y_0\mid\mathbf{x}\bigr]}\),
  implies \(y_0\) does not determine participation. No anticipation
  effects from being treated.
\end{itemize}

Bertrand et al.2004, 3 factors make serial correlated an especially
important issue in the DID context: often long-timeseries used,
dependent variable often highly positively serially correlated,
treatment variables changes very little within a state over time (often
intervention stays on).

\hypertarget{iv-solves-endogen-and-simultaneity-issues-in-ols.}{%
\subsection{\texorpdfstring{\textbf{IV}: Solves endogen-and-simultaneity
issues in
OLS.}{IV: Solves endogen-and-simultaneity issues in OLS.}}\label{iv-solves-endogen-and-simultaneity-issues-in-ols.}}

\(y=\mathbf{x}^{\prime} \boldsymbol{\beta}+u\); where
\(\mathrm{E}[\mathbf{x} u]\neq 0\), \(\boldsymbol{\beta_{OLS}}\) is
inconsistent.

\textbf{Assumptions}: Identification of \(\beta_{IV}\)\\

\textbf{(IV.1)}: \textbf{Validity}/predeterminedness:
\(\mathrm{E}[\mathbf{z} u]=0\); \textbf{(IV.2)}: \textbf{Relevance}.
\textcolor{blue}{(a)}
\(\text { rank } E\left[\mathbf{z z}^{\prime}\right]=L\);
\textcolor{blue}{(b)}
\(\text { rank } E\left[\mathbf{z} x^{\prime}\right]=K\); where
\(L \geqslant K\). And, we have
\(\widehat{\boldsymbol{\beta}}_{I V}=\left[\mathbf{Z^\prime} \mathbf{X}\right]^{-1} [\mathbf{Z^\prime} y]\)
\(\widehat{\boldsymbol{\beta}}_{2SLS}=\left(\hat{\mathbf{X}}^{\prime} \mathbf{X}\right)^{-1} \hat{\mathbf{X}}^{\prime}{\mathbf{y}}\)
where
\(\hat{\mathbf{X}}=\mathrm{\mathbf{P_Z X}}= \mathbf{Z}\left(\mathbf{Z}^{\prime} \mathbf{Z}\right)^{-1} \mathbf{Z}^{\prime} \mathbf{X}\).
\(\widehat{\boldsymbol{\beta}}_{2SLS} = \widehat{\boldsymbol{\beta}}_{IV}\;; if \; L = K\).\\
\textcolor{blue}{Homogeneous/Heterogenoues(LATE IV Estimator) treatment effects}\\
\(\text{For a simple model}\; Y_{i}=\alpha+\rho_{i} D_{i}+\epsilon_{i}\);
where treatment \(\;D_{i}=\pi_{0}+\pi_{1 i} z_{i}+\zeta_{i}\)

\textbf{Assumptions}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{(Independence)}: \(z_{i}\) is as good as randomly assigned; it
  is independent of the vector of potential outcomes and treatment
  assignments.
  \(\left\{\mathrm{Y}_{i}\left(\mathrm{D}_{1 i}, 1\right), \mathrm{Y}_{0 i}\left(\mathrm{D}_{0 i}, 0\right), \mathrm{D}_{1 i}, \mathrm{D}_{0 i}\right\} \perp \perp \mathrm{Z}_{i}.\)
  Independence implies that the \textbf{first-stage} is the average
  causal effect of \(\mathrm{Z}_{i}\) on \(\mathrm{D}_{i}\) \[
  \begin{aligned}
  E\left[\mathrm{D}_{i} \mid \mathrm{z}_{i}=1\right]-E\left[\mathrm{D}_{i} \mid \mathrm{z}_{i}=0\right] = \\ E\left[\mathrm{D}_{1 i} \mid \mathrm{z}_{i}=1\right]-E\left[\mathrm{D}_{0 i} \mid \mathrm{z}_{i}=0\right]
  =E\left[\mathrm{D}_{1 i}-\mathrm{D}_{0 i}\right]
  \end{aligned}
  \] Independence is also \textbf{sufficient} for a causal
  interpretation of the \textbf{reduced form}---the causal effect of the
  instrument on the dependent variable. Specifically,
  \(E\left[\mathrm{Y}_{i} \mid \mathrm{z}_{i}=1\right]-E\left[\mathrm{Y}_{i} \mid \mathrm{Z}_{i}=0\right]=E\left[\mathrm{Y}_{i}\left(\mathrm{D}_{1 i}, 1\right)-\mathrm{Y}_{i}\left(\mathrm{D}_{0 i}, 0\right)\right]\)
\item
  \textbf{Exclusion Restriction (ER)}
  \(\mathrm{Y}_{i}(d, 0)=\mathrm{Y}_{i}(d, 1) \equiv \mathrm{Y}_{d i}\)
  for \(d=0,1\). instrument operates through a single known causal
  channel. In homogeneity, ER is expressed by
  \(E[z_i\varepsilon_i] = 0\).
\item
  \textbf{(First-stage)}
  \(E\left[\mathrm{D}_{1 i}-\mathrm{D}_{0 i}\right] \neq 0\)
\item
  \textbf{(Monotonicity)} \(\mathrm{D}_{1 i}-\mathrm{D}_{0 i} \geq 0\),
  or vice versa.
  \(\rightarrow E[\mathrm{D}_{1 i}-\mathrm{D}_{0 i}]=P(D_{1i}>D_{0i})\),
  means that while the instrument may have no effect on some people, all
  of those who are affected are affected in the same way. Then, \[
  \begin{aligned}
  \frac{E\left[Y_{i} \mid z_{i}=1\right]-E\left[Y_{i} \mid z_{i}=0\right]}{E\left[D_{i} \mid z_{i}=1\right]-E\left[D_{i} \mid z_{i}=0\right]}
  \end{aligned}
      \]
\end{enumerate}

The ER is distinct from the claim that the instrument is (as good as)
randomly assigned. Rather, it is a claim about a unique channel for
causal effects of the instrument. A failure of \textbf{monotonicity}
means the instrument pushes some people into treatment while pushing
others out---(\textbf{defiers}).

\begin{itemize}
\tightlist
\item
  \textbf{Compliers}. The subpop w/ \(d_{1i} = 1\) \& \(d_{0i} = 0\):
\item
  \textbf{Always-takers (AT)}. The subpop w/ \(d_{1i} =d_{0i} = 1\):
\item
  \textbf{Never-takers (NT)}. The subpop w/ \(d_{1i} =d_{0i} = 0\):
\end{itemize}

without adding further assumptions (e.g., constant causal effects), LATE
is not informative about effects on NT \& AT because, by definition,
treatment status for these two groups is unchanged by the instrument
(random assignment).

\textbf{LATE} is the effect of treatment on the \textbf{population of
compliers}. The average causal effect on compliers is not usually the
same as the ATT. The treated consist of either AT or compliers with the
\textbf{instrument switched on}.

\[\begin{small}
\begin{aligned}
\overbrace{E\left[\mathrm{Y}_{1 i}-\mathrm{Y}_{0 i} \mid \mathrm{D}_{i}=1\right]}^{\text {effect on the treated }}
= \overbrace{E\left[\mathrm{Y}_{1 i}-\mathrm{Y}_{0 i} \mid \mathrm{D}_{0 i}=1\right]}^{\text {effect on AT }}P\left[\mathrm{D}_{0 i}=1 \mid \mathrm{D}_{i}=1\right] \\
+ \underbrace{E\left[\mathrm{Y}_{1 i}-\mathrm{Y}_{0 i} \mid \mathrm{D}_{1 i}>\mathrm{D}_{0 i}\right]}_{\text {effect on compliers }}P\left[\mathrm{D}_{1 i}>\mathrm{D}_{0 i}, \mathrm{z}_{i}=1 \mid \mathrm{D}_{i}=1\right]
\end{aligned}
\end{small}\]

The \textbf{ATT} \textcolor{blue}{(ATU)} is a weighted average. of
effects on \textbf{AT \& compliers}
\textcolor{blue}{(NT and compliers)}. population ATE = a weighted
average of effects on compliers, AT, \& NT.\\
The size of a compliers group is the Wald 1st-stage,
\(P(D_{i1} > D_{i0})=E\left[D_{1 i} \mid z_i = 1\right] -E\left[D_{0 i}\mid z_{i}=0\right]\).
The proportion of the treated who are compliers is given by the
1st-stage, times the probability that the instrument is switched on
\(P[z_i =1]\), divided by the prop treated \(P[D_i = 1]\).\\
\textbf{Staiger \& Stock (1997)} F \textless{} 10 may indicate problems
with finite sample bias---weak instrument. IV may be more inconsistent
than OLS when the correlated between the instrument and the regressor is
low. IV \textbf{less precise} than OLS.
\(variable(\hat{\beta}_{IV})\ge variable(\hat{\beta}_{OLS})\) unless
\(correlated(x, z) = 1\).

\hypertarget{lpm-logit-probit}{%
\subsection{LPM Logit Probit}\label{lpm-logit-probit}}

For general binary dependent variable model
\(p(\mathbf{x})=\operatorname{Pr}(y=1 \mid \mathbf{x})=\mathbf{x}^{\prime} \boldsymbol{\beta}\)\\
Marginal effects of a \(x_{j}\)
:\(\frac{\partial \operatorname{Pr}(y=1 \mid \mathbf{x})}{\partial x_{j}} = F'(x'\beta)\beta_{j}\)

\begin{itemize}
\tightlist
\item
  Ignores discreteness \& will treat the dependent variable as
  continuous.
\item
  Does not constrain predicted probabilities to lie between 0 \& 1.
\item
  Does not take into account that outcomes might not be naturally
  ordered
\item
  \textcolor{blue}{(+)} Interest is in analyzing partial effects
  averaged over the distribution of x.
\item
  \textcolor{blue}{(+)} The \(x_j\) take on only a few values \& the
  model is saturated. Thus, the CEF is (close to) a linear function of
  the regressors.
\item
  For latent index model
  \(z: \ F(z) = z; F(z) = \Phi (z); F(z) = 1/(1+exp(-z))\)
\item
  The MLE is consistent if the CEF is correctly specified:
  \(E[y|x] = F(x'\beta)\)
\item
  Identification of the single-index model requires a restriction of the
  variable (u) to secure uniqueness of \(\beta\). In the probit model
  the error variance is set to one.
\item
  Also the mean of the error distribution needs to be normalized:
  usually to zero.
\end{itemize}

For non-linear models, where

\(F^{\prime}\left(\mathbf{x}^{\prime} \boldsymbol{\beta}\right) \neq c\)
the me will vary with the evaluation point \(x\) and the choice of
\(F(\cdot)\):\\
1.
\((\mathrm{AME}): N^{-1} \sum_{i} F^{\prime}\left(\mathbf{x}_{i}^{\prime} \widehat{\boldsymbol{\beta}}\right) \widehat{\beta}_{j}\)\\
2. The average of the regressors
\((\mathrm{MEM}): F^{\prime}\left(\overline{\mathrm{x}}^{\prime} \widehat{\beta}\right) \widehat{\beta}_{j}\)\\
3. The marginal effect at a representative point
\(\mathbf{x}_{1}(\mathrm{MER}): F^{\prime}\left(\mathbf{x}_{1}^{\prime} \widehat{\boldsymbol{\beta}}\right) \widehat{\beta}_{j}\)

\textbf{Threats to Internal Validity}

(1.) Failure to Randomize: If the subjects are not randomly assigned to
the treatment group. (2.) Failure to Follow the Treatment
Protocol--defiers (3.) Attrition: If subjects systematically drop out of
the study. (4.) Experimental effects: If subjects know that they are in
an experiment. (5.) Small Sample Sizes

\textbf{Threats to External Validity}

(1.) Unrepresentative Sample, and Program or Policy (2.) GE effects: If
market and/or environmental conditions cannot be kept constant when an
internally valid program is implemented broadly, external validity may
be doubtful.

\hypertarget{rdd}{%
\subsection{RDD}\label{rdd}}

\textbf{RD} methods exploit precise knowledge of the rules determining
assignment to treatment around a threshold val of a variable.
\textbf{SRDD}: treatment status is \textbf{deterministic} and a

\textbf{discontinuous} fun of covariate. We do not observe both treated
and untreated values of \(x_{i}\) for individuals, thus validity of
\(\mathrm{RD}\) relies on our willingness to extrapolate in a
neighborhood of \(c\). model.eq:
\(Y_{i}=\alpha+\beta x_{i}+\tau D_{i}+\eta_{i}\) \textbf{FRDD} exploits
discontinuities in the prob or expected val of treatment conditional on
a covariate. Thus, the discontinuity becomes an IV for treatment and we
use 2SLS.

\textbf{Matching} estimators are normally used when 1. The interest is
in the ATT rather than the ATE. 2. Randomization into treatment is not
possible. 3. There is a large pool of potential control subjects.

\end{document}
